{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec5f5a27",
   "metadata": {},
   "source": [
    "# Supervised Learning with KNNs and the Iris Dataset\n",
    "\n",
    "In this demo we will be using the **[Iris Dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)** to build a supervised learning model for a multiclass classification task.\n",
    "\n",
    "As discussed in the session, the dataset consists of \n",
    "- 3 different types of iris flowers (setosa, versicolour, and virginica), with \n",
    "- 4 features (petal length, petal width, sepal length, and sepal width), and \n",
    "- 50 samples for each flower, \n",
    "- stored in a 150x4 numpy.ndarray\n",
    "\n",
    "For this demo, we'll be using the **K-Nearest Neighbour (KNN)** model. \n",
    "\n",
    "The following will be covered in this demo: \n",
    "- Initial setup \n",
    "- Loading and exploring the data\n",
    "- Splitting the dataset into train and test datasets\n",
    "- Creating a KNN classifier\n",
    "- Evaluating the performance of the classifier\n",
    "- Improviing the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1f928",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febfc448",
   "metadata": {},
   "source": [
    "## Step 0) Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966251f9",
   "metadata": {},
   "source": [
    "Install the required libraries if you don't already have them installed. To install them, uncomment the following lines from the code block and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc5d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy==1.26.*\n",
    "# !pip install pandas==2.1.*\n",
    "# !pip install matplotlib==3.8.*\n",
    "# !pip install seaborn==0.12.*\n",
    "# !pip install sklearn==1.3.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3366d833",
   "metadata": {},
   "source": [
    "Import required libraries. We will be using the following: \n",
    "- [NumPy](https://numpy.org/doc/stable/index.html)\n",
    "- [pandas](https://pandas.pydata.org/)\n",
    "- [matplotlib](https://matplotlib.org/stable/tutorials/pyplot.html)\n",
    "- [seaborn](https://seaborn.pydata.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434edd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "# Print the versions of the libraries you've just imported\n",
    "print(f'numpy: {np.__version__}')\n",
    "print(f'pandas: {pd.__version__}')\n",
    "print(f'matplotlib: {matplotlib.__version__}')\n",
    "print(f'seaborn: {sns.__version__}')\n",
    "print(f'sklearn: {sklearn.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e041b679",
   "metadata": {},
   "source": [
    "Setting a constant for the [random state](https://medium.com/mlearning-ai/what-the-heck-is-random-state-24a7a8389f3d). \n",
    "\n",
    "This is not required, but since some algorithms rely on random number generators, the outputs can vary across runs. By passing in the same random state to those functions, allows for reproducable outputs.\n",
    "\n",
    "Any guesses on why its set to [42](https://grsahagian.medium.com/what-is-random-state-42-d803402ee76b)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab2379",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108ce019",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61239638",
   "metadata": {},
   "source": [
    "## Step 1) Load and explore the data\n",
    "\n",
    "We will be using the [Iris Dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html) for this demo. This can be imported from [scikit-learn](https://scikit-learn.org/stable/index.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f69208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a7931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479fa442",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70337223",
   "metadata": {},
   "source": [
    "The dataset comes with lots of useful information, including things like the description of the dataset, names of the categories (targets), and names of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d3b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ca821",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a670101",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75595f5",
   "metadata": {},
   "source": [
    "Create a pandas dataframe from the dataset. This way we can visualise the data more easily. \n",
    "Since the 'targets' in the dataset are numeric by default (recall one-hot encoding?), we can apply some logic to create a column with text categories so its more readable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.DataFrame(data = iris['data'], columns = iris['feature_names'])\n",
    "iris_df['Iris type'] = iris['target']\n",
    "iris_df['Iris name'] = iris_df['Iris type'].apply(lambda x: 'Setosa' if x == 0 else ('Versicolour' if x == 1 else 'Virginica'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029eff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(iris_df, hue=\"Iris name\", height=4, aspect=1.5) \\\n",
    "   .map(plt.scatter, \"sepal length (cm)\", \"sepal width (cm)\") \\\n",
    "   .add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffeb004",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(iris_df, hue=\"Iris name\", height=4, aspect=1.5) \\\n",
    "   .map(plt.scatter, \"petal length (cm)\", \"petal width (cm)\") \\\n",
    "   .add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3cd1e2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d36cf",
   "metadata": {},
   "source": [
    "## Step 2) Split the dataset into train and test datasets\n",
    "\n",
    "Since we have a single dataset, we will need to split it into train and test datasets. \n",
    "\n",
    "It is very **important** to make the split before apply any transformations to the dataset or feeding it into the model. This is because we do not want any information from the test dataset to influence any part of the training process.\n",
    "\n",
    "First, lets create X (samples/inputs) and y (targets/outputs) from the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193a3151",
   "metadata": {},
   "source": [
    "The easiest way to create train and test dataset is to use the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a14c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8d0753",
   "metadata": {},
   "source": [
    "We can create a test dataset using 20% of the entire dataset. That means, 80% of the data will be used for training. If we need to create a validation split as well, then we can pass the X_train and y_train to the same function, and create another split.\n",
    "\n",
    "Notice that we are setting the random state here. This is so that we can reproduce the same train test split each time we call this function - makes things easier in demos! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cbe7c4",
   "metadata": {},
   "source": [
    "Let's create a simple function to count the frequency of classes in each split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3591c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frequency_of_classes(l): \n",
    "    print('# Samples of 0: ', np.count_nonzero(l == 0))\n",
    "    print('# Samples of 1: ', np.count_nonzero(l == 1))\n",
    "    print('# Samples of 2: ', np.count_nonzero(l == 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bcaae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_frequency_of_classes(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13fdfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_frequency_of_classes(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b10c37",
   "metadata": {},
   "source": [
    "We can see that the frequency of features from different classes is not uniform in this train/test split. In some cases, this might be desired, in others this might not be. \n",
    "\n",
    "If we want a uniform distribution of samples from each class, we can use the **stratify** parameter for the train_test_split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a3d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbc916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_frequency_of_classes(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e8fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_frequency_of_classes(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea06473",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0b7ef",
   "metadata": {},
   "source": [
    "## Step 3) Create the KNN classifier\n",
    "\n",
    "We can import the KNN classifier from [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07106881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982748ce",
   "metadata": {},
   "source": [
    "The classifier takes a few hyperparameters. The main ones are: \n",
    "- **n_neighbors**: Value of K for the classifier. Number of neighbors to use by default for kneighbors queries\n",
    "- **weights**: Weight functions used for prediction. \n",
    "    - uniform: All points in each neighborhood are weighted equally.\n",
    "    - distance: weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away\n",
    "- **p**: Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d7c721",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=2, weights='uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925e293b",
   "metadata": {},
   "source": [
    "**Training** the model is incredibly simple! All we need to do is call the **fit()** function on the classifier object that we just created, and pass in the train data (X_train) and targets (y_train). \n",
    "\n",
    "Since this is a supervised learning model, we need to pass te targets. We'll see in future sessions that training unsupervised learning models follows the same process without the need to pass in any targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4718de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127827e6",
   "metadata": {},
   "source": [
    "Similarily, once we have trained the model, we can simply call the **predict()** function along with the test samples (X_test) to get a list of predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8bf730",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af346d0",
   "metadata": {},
   "source": [
    "We can get a bit of insight into how the model made its predictions by calling the **predict_proba()** function. More information on how this classifier breaks ties can be found [here](https://stats.stackexchange.com/questions/144718/how-does-scikit-learn-resolve-ties-in-the-knn-classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9bf4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = knn.predict_proba(X_test)\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055e2366",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c81e17",
   "metadata": {},
   "source": [
    "## Step 4) Evaluate the Model Performance\n",
    "\n",
    "We will evaluate the performance of the model primarily by looking at the **accuracy**. For this demo, we will also create a confusion matrix from the predictions. \n",
    "\n",
    "Fortunately, sklearn provides a lot of performance evaluation [metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) for all sorts of machine learning models, including the accuracy and confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a56863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c70a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2450cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a16b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=iris['target_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaae8750",
   "metadata": {},
   "source": [
    "Lets try to see why that happened. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca00d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('True\\tPredict\\tProbability')\n",
    "for _y_test, _y_pred, _pred_prob in zip(y_test, y_pred, pred_prob): \n",
    "    print(f'{_y_test}\\t{_y_pred}\\t{_pred_prob}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c9c17",
   "metadata": {},
   "source": [
    "Because the KNN model is quite simple and intuitive, it is possible for us to do this sort of analysis. However, this is not always possible for all classifiers, especially when working with large amounts of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bc7a1f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb6bc05",
   "metadata": {},
   "source": [
    "## Step 5) Improve model performance\n",
    "\n",
    "So far we tried using K = 2 for the KNN classifier. Changing this value will lead to different classifiers, which will have lead to different performance against the test dataset. \n",
    "\n",
    "So, we can use K-fold cross validation to validate the performance of different hyperparameters (in this case, values of K). \n",
    "\n",
    "We can start by importing the [Grid Search Cross Validator](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) from sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7424cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcfc980",
   "metadata": {},
   "source": [
    "In this case, we'll try values for k between 1 and 11 (recall the rule of thumb for an optimal value of K from the slides!). And we'll use 10 splits in the cross validation process. That means \n",
    "\n",
    "- The train set will be split into 10 subsets. \n",
    "- The CV will loop over the datasets 10 times, each time, it will pick a different subset to use as a validation set, and use the other 9 to train the model. \n",
    "- The mean performance of the models will be the output \n",
    "- The process will be repeated for each hyperparameter (in this case, value of K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "cv = GridSearchCV(knn, {'n_neighbors': [1,2,3,4,5,6,7,8,9,10,11]}, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88e5925",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059cf3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a291c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d22041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,12), cv.cv_results_['mean_test_score'])\n",
    "plt.xticks(range(1,12))\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443703e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a48209",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=iris['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f9496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
